import os
import pandas as pd
from finrl.agents.stablebaselines3.models import DRLAgent
import torch
from env_etf_option import OptionStraddleEnv
from Networks import HybridOptionExtractor as HybridFeatureExtractor
from dataclasses import dataclass
from finTool.single_window_account_fast import single_Account
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv
import numpy as np
from stable_baselines3.common.callbacks import BaseCallback
import sys
from pathlib import Path
from datetime import datetime, timedelta

def setup_miniqmt_import_root():
    """
    é€’å½’æŸ¥æ‰¾ 'miniQMT' æ–‡ä»¶å¤¹ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ° sys.path ä¸­ï¼Œ
    ä»è€Œå…è®¸ä½¿ç”¨ miniQMT ä¸ºæ ¹çš„ç»å¯¹å¯¼å…¥ã€‚
    """
    # 1. è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
    # stack[0] æ˜¯å½“å‰æ­£åœ¨æ‰§è¡Œçš„å¸§ï¼Œå…¶ f_globals['__file__'] æ˜¯è„šæœ¬è·¯å¾„
    try:
        # è·å–è°ƒç”¨æ­¤å‡½æ•°çš„è„šæœ¬çš„è·¯å¾„
        calling_script_path = Path(sys._getframe(1).f_globals['__file__']).resolve()
    except KeyError:
        # å¦‚æœåœ¨äº¤äº’å¼ç¯å¢ƒæˆ–æŸäº›ç‰¹æ®Šç¯å¢ƒä¸­ï¼Œå¯èƒ½æ— æ³•è·å–æ–‡ä»¶è·¯å¾„ï¼Œåˆ™é€€å‡º
        print("âš ï¸ è­¦å‘Š: æ— æ³•ç¡®å®šå½“å‰è„šæœ¬è·¯å¾„ï¼Œè·³è¿‡è·¯å¾„è®¾ç½®ã€‚")
        return
    
    current_path = calling_script_path
    miniqmt_root = None
    
    # 2. å‘ä¸Šé€’å½’æŸ¥æ‰¾
    # current_path.parents æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰çˆ¶ç›®å½•çš„åºåˆ—
    for parent in [current_path] + list(current_path.parents):
        if parent.name == 'miniQMT':
            miniqmt_root = parent
            break
        
    # 3. æ£€æŸ¥å¹¶æ·»åŠ è·¯å¾„
    if miniqmt_root:
        # å°†æ‰¾åˆ°çš„ miniQMT ç›®å½•æ·»åŠ åˆ° sys.path
        miniqmt_root_str = str(miniqmt_root)
        if miniqmt_root_str not in sys.path:
            sys.path.insert(0, miniqmt_root_str)
            print(f"âœ… æˆåŠŸå°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°æœç´¢è·¯å¾„: {miniqmt_root_str}")
        else:
            # å·²ç»æ·»åŠ è¿‡ï¼Œæ— éœ€é‡å¤æ·»åŠ 
            # print(f"â„¹ï¸ é¡¹ç›®æ ¹ç›®å½•å·²åœ¨æœç´¢è·¯å¾„ä¸­: {miniqmt_root_str}")
            pass
    else:
        print("âŒ é”™è¯¯: æœªèƒ½åœ¨å½“å‰è·¯å¾„æˆ–å…¶ä»»ä½•çˆ¶ç›®å½•ä¸­æ‰¾åˆ° 'miniQMT' æ–‡ä»¶å¤¹ã€‚")
setup_miniqmt_import_root()

class FinancialMetricsCallback(BaseCallback):
    def __init__(self, verbose=1):
        super(FinancialMetricsCallback, self).__init__(verbose)
        # ç”¨äºå­˜å‚¨æœ¬è½®é‡‡æ ·ä¸­æ‰€æœ‰æ­¥éª¤çš„æŒ‡æ ‡
        self.step_buffer = {"sharpe": [], "simple_ann": [], "log_ann": []}

    def _on_step(self) -> bool:
        # è·å–æ‰€æœ‰å¹¶è¡Œç¯å¢ƒçš„å®æ—¶ info
        for info in self.locals.get("infos", []):
            if "running_metrics" in info:
                m = info["running_metrics"]
                self.step_buffer["sharpe"].append(m["sharpe"])
                self.step_buffer["simple_ann"].append(m["simple_ann"])
                self.step_buffer["log_ann"].append(m["log_ann"])
        return True

    def _on_rollout_end(self) -> None:
        # åœ¨ä¸€ä¸ªé‡‡æ ·å‘¨æœŸï¼ˆå¦‚ 2048 æ­¥ï¼‰ç»“æŸæ—¶æ‰“å°å‡å€¼
        if len(self.step_buffer["sharpe"]) > 0:
            avg_metrics = {k: np.mean(v) for k, v in self.step_buffer.items()}
            
            # è®°å½•åˆ° SB3 çš„ Loggerï¼Œä½¿å…¶åœ¨æ§åˆ¶å°è¡¨æ ¼æ˜¾ç¤º
            self.logger.record("finance/running_sharpe_avg", float(avg_metrics["sharpe"]))
            self.logger.record("finance/ann_return_simple", float(avg_metrics["simple_ann"]))
            self.logger.record("finance/ann_return_log_cont", float(avg_metrics["log_ann"]))
            
            if self.verbose > 0:
                print(f"\n[Running Metrics] Iteration Summary:")
                print(f"Avg Sharpe: {avg_metrics['sharpe']:.4f} | "
                      f"Simple Ann: {avg_metrics['simple_ann']:.2%} | "
                      f"Log Ann: {avg_metrics['log_ann']:.2%}")
            
            # é‡ç½®ç¼“å†²åŒº
            for k in self.step_buffer: self.step_buffer[k] = []

@dataclass
class Config:
    pretrained_path: str = "./miniQMT/DL/preTrain/weights/preMOE_best_dummy_data_32_4.pth"
    window_size: int = 32
    pre_len: int = 4
    n_variates: int = 13
    d_router: int = 128
    num_workers: int = 1

    # env
    benchmark: str = '510050'
    fee: float = 1.3
    init_capital: float = 100000.0

    # dl
    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'

def get_option_pairs():
    """
    æ‰«æç›®å½•ï¼Œç”Ÿæˆä»»åŠ¡æ¸…å•ã€‚è¿™éƒ¨åˆ†é€»è¾‘ç›´æ¥å¤ç”¨ä½  PPO_GPT ç»“å°¾çš„éƒ¨åˆ†ã€‚
    """

    # 1. åŠ è½½åŸå§‹æ•°æ®
    dtype = {
        'call': str, 'put': str,
        'call_strike': float, 'put_strike': float,
        'call_open': str, 'call_expire': str,
    }
    df = pd.read_excel('./miniQMT/datasets/all_label_data/20251213_train.xlsx', dtype=dtype)

    # æ’é™¤åå•
    exclude_list = [
        '10007347', '10007466', '10007467', '10006436', '10007346', '10006435', '10007465', 
        '10007726', '10007725', '10007724', '10008052', '10007723', '10006434', '10007722', 
        '10008051', '10007345', '10007721', '10007464', '10007344', '10007988', '10006433', 
        '10006820', '10007720', '10007987', '10006746', '10006745', '10007463', '10006432', '10007719'
    ]
    # 2. åŠ¨æ€åˆ†ç±»é‡‡æ ·é€»è¾‘
    all_pairs = []
    # åˆ†ç±»æ¡¶ï¼Œç›®æ ‡æ€»æ•°çº¦ 20 ä¸ª
    buckets = {"ITM": [], "ATM": [], "OTM": []}
    target_per_bucket = 20

    # é¢„åŠ è½½ä¸€ä¸ªè´¦æˆ·ç”¨äºè·å–åˆå§‹æ ‡çš„ä»·æ ¼
    temp_account = single_Account(100000, stockList=['510050'])

    # æ‰“ä¹±åŸå§‹æ•°æ®é¡ºåºï¼Œä¿è¯é‡‡æ ·çš„éšæœºæ€§
    # df = df.sample(frac=1).reset_index(drop=True)

    for index, row in df.iterrows():
        call, put = row['call'], row['put']
        if call in exclude_list or put in exclude_list:
            continue

        # æ—¶é—´é€»è¾‘
        start_str, expire_str = row['call_open'], row['call_expire']
        start_dt = datetime.strptime(start_str, "%Y%m%d")
        expire_dt = datetime.strptime(expire_str, "%Y%m%d")
        
        if (expire_dt - start_dt).days <= 40:
            continue

        # è®¡ç®—åˆå§‹ Moneyness (è¡Œæƒä»· / æ ‡çš„ä»·æ ¼)
        # å‡è®¾ start_time ä¸ºå¼€ç›˜ 10:00:00
        start_time_full = start_str + '100000'
        try:
            spot_price = temp_account.getOpenPrice('510050', start_time_full)
            if spot_price <= 0: continue
            
            # ä»¥ Call çš„è¡Œæƒä»·è®¡ç®—
            moneyness = row['call_strike'] / spot_price
            
            # ç®€å•åˆ†ç±»ï¼š0.98-1.02 ä¸ºå¹³å€¼ï¼Œå¤§äº 1.05 ä¸ºè™šå€¼ï¼Œå°äº 0.95 ä¸ºå®å€¼
            if 0.97 <= moneyness <= 1.03:
                cat = "ATM"
            elif moneyness > 1.03:
                cat = "OTM"
            else:
                cat = "ITM"
            
            # å¡«æ¡¶
            if len(buckets[cat]) < target_per_bucket:
                end_time_full = (expire_dt - timedelta(days=20)).strftime('%Y%m%d') + '150000'
                buckets[cat].append({
                    'call': call, 'put': put,
                    'start_time': start_time_full,
                    'end_time': end_time_full,
                    'steps': int(row['steps']),
                    'init_moneyness': moneyness
                })
        except:
            continue

        # if sum(len(v) for v in buckets.values()) >= 21:
        #     break

    # åˆå¹¶é‡‡æ ·ç»“æœ
    for cat_list in buckets.values():
        all_pairs.extend(cat_list)

    return all_pairs

def train():
    cfg = Config(
        pretrained_path="./miniQMT/DL/preTrain/weights/preMOE_best_dummy_data_32_4.pth",
        window_size=32,
        pre_len=4,
        n_variates=13,
        d_router=128,
        init_capital=100000,
        num_workers=2)
    
    pairs = get_option_pairs()
    
# --- ä¿®æ­£åçš„ç¯å¢ƒå‘é‡åŒ–åŒ…è£… ---
    def make_env():
        return OptionStraddleEnv(option_pairs_list=pairs, cfg=cfg)

    # æ›¿ä»£ get_sb3_env çš„æ ‡å‡† SB3 æ–¹æ³•
    if cfg.num_workers > 1:
        env_train = SubprocVecEnv([make_env for _ in range(cfg.num_workers)])
    else:
        env_train = DummyVecEnv([make_env])

    fin_metrics_cb = FinancialMetricsCallback(verbose=1)

    # 4. åˆå§‹åŒ– DRLAgent
    agent = DRLAgent(env=env_train)
    
    policy_kwargs = dict(
        features_extractor_class=HybridFeatureExtractor,
        features_extractor_kwargs=dict(cfg=cfg),
        net_arch=dict(pi=[256, 256], vf=[256, 256]),
    )
    
    # --- ğŸ”¥ å…³é”®ä¿®æ­£ï¼šè¶…å‚æ•°å¿…é¡»æ”¾åœ¨ model_kwargs å­—å…¸ä¸­ ---
    n_steps = 256
    model_kwargs = {
        "learning_rate": 1e-4,
        "n_steps": n_steps,
        "batch_size": 256,
        "ent_coef": 0.01,
        "clip_range": 0.15,
        "gamma": 0.99,
        "gae_lambda": 0.95
    }

    num_epochs = 1
    total_training_steps = num_epochs * n_steps * cfg.num_workers

    #   è·å– PPO æ¨¡å‹
    model = agent.get_model(
        model_name="ppo", 
        policy="MultiInputPolicy", # å¿…é¡»æ˜¯è¿™ä¸ªæ”¿ç­–ï¼l
        policy_kwargs=policy_kwargs,
        model_kwargs=model_kwargs, # ä¼ é€’ä¿®æ­£åçš„å­—å…¸
        verbose=1,
        tensorboard_log="./miniQMT/DL/results"
    )

    
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ! æ€»æ­¥æ•°: {total_training_steps} (çº¦ {num_epochs} ä¸ªæ›´æ–°å‘¨æœŸ)")
    print("ğŸš€ å¯åŠ¨è®­ç»ƒï¼Œå·²å¼€å¯åŒå£å¾„å¹´åŒ–æ”¶ç›Šç›‘æ§...")
    model = agent.train_model(
        model=model, 
        tb_log_name="ppo_finrl_fix", 
        total_timesteps=total_training_steps,
        callbacks=[fin_metrics_cb]
    )

    model.save("ppo_option_final_model")
    print("âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜ã€‚")
    print(0 / 0)

if __name__ == "__main__":
    train()